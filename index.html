<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="TraveLER can traverse, locate, evaluate, and replan to answer questions about videos.">
  <meta name="keywords" content="TraveLER, LLM, Agents, Videos">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>TraveLER: A Modular Multi-LMM Agent Framework for Video Question-Answering</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <!-- <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script> -->

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <!-- <link rel="stylesheet" href="./static/css/bulma-carousel.min.css"> -->
  <!-- <link rel="stylesheet" href="./static/css/bulma-slider.min.css"> -->
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-2 publication-title has-text-black">TraveLER: A Modular Multi-LMM Agent Framework for Video Question-Answering</h1>
          <div class="is-size-4 publication-authors">
            <span class="author-block">
              EMNLP 2024
            <span class="author-block">
          </div>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://chuyishang.com">Chuyi Shang*</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://amosyou.com">Amos You*</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://people.eecs.berkeley.edu/~sanjayss/">Sanjay Subramanian</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="https://people.eecs.berkeley.edu/~trevor/">Trevor Darrell</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="https://roeiherz.github.io/">Roei Herzig</a><sup>1</sup>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>University of California, Berkeley</span>
          </div>
          <div class="is-size-6 publication-authors">
            <span class="author-block"><sup>*</sup>Equal Contribution</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/abs/2404.01476"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Video Link. -->
              <span class="link-block">
                <a href="https://www.youtube.com/watch?v=n_KGHYOE77w"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/traveler-framework/TraveLER"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <video id="teaser" autoplay muted controls playsinline height="100%">
        <source src="./static/videos/teaser.mp4#t=3"
                type="video/mp4">
      </video>
      <br>
      <br>
      <h2 class="subtitle has-text-centered">
        <b>TraveLER</b> can <b>trav</b>erse, <b>l</b>ocate, <b>e</b>valuate, and <b>r</b>eplan to answer questions about videos.
      </h2>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-full-width">
        <h2 class="title is-4">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Recently, image-based Large Multimodal Models (LMMs) have made significant progress in video question-answering (VideoQA) using a frame-wise approach by leveraging large-scale pretraining in a zero-shot manner. Nevertheless, these models need to be capable of finding relevant information, extracting it, and answering the question simultaneously. Currently, existing methods perform all of these steps in a single pass without being able to adapt if insufficient or incorrect information is collected. To overcome this, we introduce a modular multi-LMM agent framework based on several agents with different roles, instructed by a Planner agent that updates its instructions using shared feedback from the other agents. Specifically, we propose <i>TraveLER</i>, a method that can create a plan to <b>Trave</b>rse through the video, ask questions about individual frames to <b>L</b>ocate and store key information, and then <b>E</b>valuate if there is enough information to answer the question. Finally, if there is not enough information, our method is able to <b>R</b>eplan based on its collected knowledge. Through extensive experiments, we find that the proposed <i>TraveLER</i> approach improves performance on several VideoQA benchmarks without the need to fine-tune on specific datasets.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">

    <!-- overview -->
    <div class="column is-full-width">
      <h2 class="title is-4">Overview</h2>
    </div>
    <br>
    <div class="columns is-centered">
      <div class="column is-four-fifths">
        <img src="./static/images/fig1.png">
      </div>
    </div>
    <div class="column is-full-width">
      <p>
        Our proposed framework aims to answer the question by collecting relevant information from keyframes through interactive question-asking. To accomplish this, several agents (in colored boxes) with different roles interact (left-to-right in each row) over several iterations. TraveLER creates a plan (in <span style="color: blue;">blue</span>) to ‚Äútraverse‚Äù (in <span style="color: orange;">orange</span>) through the video, asks questions regarding individual frames (in <span style="color: gold;">yellow</span>) to ‚Äúlocate‚Äù and store key information and, ‚Äúevaluates‚Äù whether there is sufficient information to answer the question (in <span style="color: green;">green</span>), and ‚Äúreplans‚Äù using past collected knowledge if there is not enough information.
      </p>
    </div>
    <!-- overview -->
    
    <!-- framework -->
    <div class="column is-full-width">
      <h2 class="title is-4">Framework</h2>
    </div>
    <div class="columns is-centered">
      <div class="column is-four-fifths">
          <img src="./static/images/fig2.png">
      </div>
    </div>
    <div class="column is-full-width">
      <p>
        Our framework consists of four different modules, the Planner, Retriever, Extractor, and Evaluator. The Planner creates a plan and sends it to the Retriever. The Retriever uses the plan to select the next timestamp and sends this to the Extractor. The Extractor captions and generates questions about the timestamp, answers the questions, and saves the output in the memory bank. Finally, the Evaluator determines if there is enough information and if the plan has been followed. If yes, the Evaluator returns the answer, else the existing information is sent back to the Planner to begin a new iteration.
      </p>
    </div>
    <!-- framework -->

    <!-- results -->
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">üìä Results</h2>

        <!-- benchmarks -->
        <h3 class="title is-4">Benchmarks</h3>
        <div class="content has-text-justified">
          <p>
            We can also animate the scene by interpolating the deformation latent codes of two input
            frames. Use the slider here to linearly interpolate between the left frame and the right
            frame.
          </p>
        </div>
        <img src="./static/images/results.png">
        <br/>
        <!--/ benchmarks -->
        
        <!--/ ablations -->
        <h3 class="title is-4">Ablation</h3>
        <div class="content has-text-justified">
          <p>
            We can also animate the scene by interpolating the deformation latent codes of two input
            frames. Use the slider here to linearly interpolate between the left frame and the right
            frame.
          </p>
        </div>
        <img src="./static/images/ablation.png">
        <br/>
        <!--/ ablations -->

      </div>
    </div>
    <!--/ results -->
  </div>
</section>


<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@inproceedings{shang2024traveler,
  author    = {Shang, Chuyi and You, Amos and Subramanian, Sanjay and Darrell, Trevor and Herzig, Roei},
  title     = {TraveLER: A Modular Multi-LMM Agent Framework for Video Question-Answering},
  journal   = {EMNLP},
  year      = {2024},
}</code></pre>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link"
         href="./static/videos/nerfies_paper.pdf">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="https://github.com/keunhong" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div>
    <div class="columns is-centered has-text-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            Website code borrowed from <a href="https://github.com/nerfies/nerfies.github.io">nerfies</a>.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
